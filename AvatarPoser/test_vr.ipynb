{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "from human_body_prior.tools.rotation_tools import aa2matrot,matrot2aa,local2global_pose\n",
    "from utils import utils_transform\n",
    "import glob\n",
    "from IPython import embed\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from models.network import AvatarPoser as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "pretrained_model = torch.load('./model_zoo/avatarposer.pth')\n",
    "\n",
    "support_dir = 'support_data/'\n",
    "bm_fname_male = os.path.join(support_dir, 'body_models/smplh/{}/model.npz'.format('male'))\n",
    "dmpl_fname_male = os.path.join(support_dir, 'body_models/dmpls/{}/model.npz'.format('male'))\n",
    "num_betas = 16 # number of body parameters\n",
    "num_dmpls = 8 # number of DMPL parameters\n",
    "device = torch.device('cuda')\n",
    "body_model = BodyModel(bm_fname=bm_fname_male, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=dmpl_fname_male)\n",
    "\n",
    "model = net(input_dim=54,\n",
    "            output_dim=132,\n",
    "            num_layer=3,\n",
    "            embed_dim=256,\n",
    "            nhead = 8,\n",
    "            body_model = body_model,\n",
    "            device = device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vr_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Avatar-Compare\\AvatarPoser\\test_vr.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Avatar-Compare/AvatarPoser/test_vr.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m##########################################################################################\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Avatar-Compare/AvatarPoser/test_vr.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Avatar-Compare/AvatarPoser/test_vr.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# VR Input Format :\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Avatar-Compare/AvatarPoser/test_vr.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Avatar-Compare/AvatarPoser/test_vr.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# rotation, position data of 3 controllers\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Avatar-Compare/AvatarPoser/test_vr.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m controller_rot_global \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(vr_data)[\u001b[39m'\u001b[39m\u001b[39mcontroller_rot_global\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# (frame, num_input*3*3)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Avatar-Compare/AvatarPoser/test_vr.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m conrroller_trans_global \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(vr_data)[\u001b[39m'\u001b[39m\u001b[39mcontroller_trans_global\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vr_data' is not defined"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "\n",
    "# VR Input Format :\n",
    "# Write2DArrToZip_npy(zip, \"controller_rot_global.npy\", controller_rot_global);\n",
    "# Write2DArrToZip_npy(zip, \"controller_trans_global.npy\", controller_trans_global);\n",
    "# Write2DArrToZip_npy(zip, \"p_a.npy\", p_a);\n",
    "# Write2DArrToZip_npy(zip, \"R_a.npy\", R_a);\n",
    "# Write2DArrToZip_npy(zip, \"M.npy\", M);\n",
    "# Write2DArrToZip_npy(zip, \"aw.npy\", aw);\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# controller_rot_global.npy: (frame, 3*3*3)\n",
    "# controller_trans_global.npy: (frame, 3*3)\n",
    "# 나머지도 전부 (length, -1) 꼴로 되어있다.\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# # Anyway, we need unity_pose_rmat.npy and unity_trans.npy\n",
    "# # Or, avatar_local_pose_rmat.npy, avatar_position_global.npy, P_a.npy, R_a.npy, M.npy, aw.npy\n",
    "\n",
    "# unity coordinates \n",
    "# #unity_poses_aa = unity_poses_aa.reshape(length, -1),       # length x 22 x 3  \n",
    "# unity_trans = unity_trans.reshape(length, -1),              # length x 3             , pelvis_translation\n",
    "# unity_pose_rmat = unity_pose_rmat.reshape(length, -1),      # length x 22 x 3 x 3    , local_rotations (all)\n",
    "\n",
    "# world coordinates\n",
    "# world_pose_rotmat = world_rotmat.reshape(length, -1),       # length x 22 x 3 x 3     , world_rotation (all)\n",
    "# world_pose_transform = world_transform.reshape(length, -1), # length x 22 x 3         , world_translation (all)\n",
    "\n",
    "# avatar coordinates\n",
    "# avatar_local_pose_rmat = avatar_local_pose_rmat.reshape(length, -1), # length x 22 x 3 x 3 , avatar_local_rotation (all)\n",
    "# avatar_position_global = avatar_position_global.reshape(length, -1), # length x 22 x 3     , avatar_global_translation (all)\n",
    "        \n",
    "# network inputs\n",
    "# p_a = p_a.reshape(length, -1),                              # length x 3(ej) x 3 (pos)\n",
    "# R_a = R_a.reshape(length, -1),                              # length x 3(ej) x 3 x 3 (rotmat)\n",
    "# M = M.reshape(length, -1),                                  # length x 3 x 3(rotmat, avatar pos inverse matrix)\n",
    "# aw = aw.reshape(length, -1),                                # length x 3 (avatar pos vector) *not inverse\n",
    "\n",
    "##########################################################################################\n",
    "# WE NEED Unity_trans.npy, Unity_pose_rmat.npy !!!!\n",
    "\n",
    "###### input processing phase #####\n",
    "# rotation, position data of 3 controllers\n",
    "controller_rot_global = np.load(vr_data)['controller_rot_global'] # (frame, num_input*3*3)\n",
    "controller_trans_global = np.load(vr_data)['controller_trans_global'] # (frame, num_input*3)\n",
    "\n",
    "input_rotation_global_6d = utils_transform.matrot2sixd(vr_data.reshape(-1,3,3))\n",
    "input_rotation_velocity_matrot = torch.matmul(torch.inverse(controller_rot_global[:-1], controller_rot_global[1:]))\n",
    "input_rotation_velocity_6d = utils_transform.matrot2sixd(input_rotation_velocity_matrot.reshape(-1, 3, 3)).reshape(input_rotation_velocity_matrot.shape[0], -1, 6)\n",
    "position_global_full_gt_world = controller_trans_global.reshape(controller_trans_global.shape[0], 3, 3)\n",
    "\n",
    "num_frames = position_global_full_gt_world.shape[0]-1\n",
    "\n",
    "hmd_position_global_full_gt_list = torch.cat([\n",
    "                                                input_rotation_global_6d.reshape(num_frames,-1),\n",
    "                                                input_rotation_velocity_6d.reshape(num_frames,-1),\n",
    "                                                position_global_full_gt_world[1:].reshape(num_frames,-1), \n",
    "                                                position_global_full_gt_world[1:].reshape(num_frames,-1)-position_global_full_gt_world[:-1,].reshape(num_frames,-1)], \n",
    "                                                  dim=-1)\n",
    "\n",
    "\n",
    "##### network eval phase#####\n",
    "model.load_state_dict(pretrained_model)\n",
    "model.eval()\n",
    "\n",
    "global_orientation, joint_rotation, joint_position = model(input) # output: (num_frames, 22 * 6)\n",
    "\n",
    "\n",
    "##### make pelvis trans ##### \n",
    "pose_6d = torch.cat([global_orientation, joint_rotation],dim=1).reshape(-1,6)\n",
    "uniy_pose_rmat = utils_transform.sixd2matrot(pose_6d)\n",
    "\n",
    "# Use HMD position to calculate root trans.\n",
    "head_trans = controller_trans_global.reshape(controller_trans_global.shape[0], 3, 3)[:,0,:]\n",
    "pred_head2root = joint_position[:,15,:]\n",
    "pelv_trans = -pred_head2root+head_trans\n",
    "\n",
    "np.savez(\n",
    "        name, \n",
    "        unity_trans = pelv_trans,\n",
    "        uniy_pose_rmat = uniy_pose_rmat\n",
    ")\n",
    "\n",
    "# Make Unity_trans.npy, Unity_pose_rmat.npy\n",
    "\n",
    "\n",
    "\n",
    "# # save npz file to run vr\n",
    "# np.savez('./input.npz', output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
