{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "from human_body_prior.tools.rotation_tools import aa2matrot,matrot2aa,local2global_pose\n",
    "from utils import utils_transform\n",
    "import glob\n",
    "from IPython import embed\n",
    "import time\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pretrained model\n",
    "pretrained_model = torch.load('./model_zoo/avatarposer.pth')\n",
    "\n",
    "support_dir = 'support_data/'\n",
    "bm_fname_male = os.path.join(support_dir, 'body_models/smplh/{}/model.npz'.format('male'))\n",
    "dmpl_fname_male = os.path.join(support_dir, 'body_models/dmpls/{}/model.npz'.format('male'))\n",
    "num_betas = 16 # number of body parameters\n",
    "num_dmpls = 8 # number of DMPL parameters\n",
    "device = torch.device('cuda')\n",
    "body_model = BodyModel(bm_fname=bm_fname_male, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=dmpl_fname_male)\n",
    "\n",
    "model = net(input_dim=54,\n",
    "            output_dim=132,\n",
    "            num_layer=3,\n",
    "            embed_dim=256,\n",
    "            nhead = 8,\n",
    "            body_model = body_model,\n",
    "            device = device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2751, 132)\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "\n",
    "# VR Input Format :\n",
    "# Write2DArrToZip_npy(zip, \"controller_rot_global.npy\", controller_rot_global);\n",
    "# Write2DArrToZip_npy(zip, \"controller_trans_global.npy\", controller_trans_global);\n",
    "# Write2DArrToZip_npy(zip, \"p_a.npy\", p_a);\n",
    "# Write2DArrToZip_npy(zip, \"R_a.npy\", R_a);\n",
    "# Write2DArrToZip_npy(zip, \"M.npy\", M);\n",
    "# Write2DArrToZip_npy(zip, \"aw.npy\", aw);\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# controller_rot_global.npy: (frame, 3*3*3)\n",
    "# controller_trans_global.npy: (frame, 3*3)\n",
    "# 나머지도 전부 (length, -1) 꼴로 되어있다.\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "# # Anyway, we need unity_pose_rmat.npy and unity_trans.npy\n",
    "# # Or, avatar_local_pose_rmat.npy, avatar_position_global.npy, P_a.npy, R_a.npy, M.npy, aw.npy\n",
    "\n",
    "# unity coordinates \n",
    "# #unity_poses_aa = unity_poses_aa.reshape(length, -1),       # length x 22 x 3  \n",
    "# unity_trans = unity_trans.reshape(length, -1),              # length x 3             , pelvis_translation\n",
    "# unity_pose_rmat = unity_pose_rmat.reshape(length, -1),      # length x 22 x 3 x 3    , local_rotations (all)\n",
    "\n",
    "# world coordinates\n",
    "# world_pose_rotmat = world_rotmat.reshape(length, -1),       # length x 22 x 3 x 3     , world_rotation (all)\n",
    "# world_pose_transform = world_transform.reshape(length, -1), # length x 22 x 3         , world_translation (all)\n",
    "\n",
    "# avatar coordinates\n",
    "# avatar_local_pose_rmat = avatar_local_pose_rmat.reshape(length, -1), # length x 22 x 3 x 3 , avatar_local_rotation (all)\n",
    "# avatar_position_global = avatar_position_global.reshape(length, -1), # length x 22 x 3     , avatar_global_translation (all)\n",
    "        \n",
    "# network inputs\n",
    "# p_a = p_a.reshape(length, -1),                              # length x 3(ej) x 3 (pos)\n",
    "# R_a = R_a.reshape(length, -1),                              # length x 3(ej) x 3 x 3 (rotmat)\n",
    "# M = M.reshape(length, -1),                                  # length x 3 x 3(rotmat, avatar pos inverse matrix)\n",
    "# aw = aw.reshape(length, -1),                                # length x 3 (avatar pos vector) *not inverse\n",
    "\n",
    "##########################################################################################\n",
    "# WE NEED Unity_trans.npy, Unity_pose_rmat.npy !!!!\n",
    "\n",
    "# rotation, position data of 3 controllers\n",
    "controller_rot_global = np.load(vr_data)['controller_rot_global'] # (frame, num_input*3*3)\n",
    "conrroller_trans_global = np.load(vr_data)['controller_trans_global'] # (frame, num_input*3)\n",
    "\n",
    "# hmd_position_global_full_gt_list = torch.cat([\n",
    "#                                                 input_rotation_global_6d.reshape(num_frames,-1),\n",
    "#                                                 input_rotation_velocity_global_6d.reshape(num_frames,-1),\n",
    "#                                                 position_global_full_gt_world[1:, [15,20,21], :].reshape(num_frames,-1), \n",
    "#                                                 position_global_full_gt_world[1:, [15,20,21], :].reshape(num_frames,-1)-position_global_full_gt_world[:-1, [15,20,21], :].reshape(num_frames,-1)], \n",
    "#                                                   dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# network input must be (frame, 54)\n",
    "\n",
    "\n",
    "\n",
    "# model.load_state_dict(pretrained_model)\n",
    "# model.eval()\n",
    "\n",
    "# output = model(input)\n",
    "\n",
    "\n",
    "# # save npz file to run vr\n",
    "# np.savez('./input.npz', output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
